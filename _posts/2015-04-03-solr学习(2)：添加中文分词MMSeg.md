---
layout: default
title: solr学习(2)：添加中文分词MMSeg
comments: true
---


 mmseg4j支持最多分词，是一款很优秀的中文分词器，是用Chih-Hao Tsai 的 MMSeg 算法( http://technology.chtsai.org/mmseg/ )实现的中文分词器;MMSeg算法有两种分词方法：Simple和Complex，都是基于正向最大匹配。Complex 加了四个规则过虑;官方说：词语的正确识别率达到了 98.41%。mmseg4j 已经实现了这两种分词算法。

###准备工作

1. mmseg4j-1.9.1.zip[下载](https://code.google.com/p/mmseg4j/downloads/list)

###分布步骤

1. 解压mmseg4j-1.9.1.zip，并将mmseg解压后dist目录中的所有jar文件（包含3个jar文件：mmseg4j-analysis-1.9.1.jar，mmseg4j-core-1.9.1.jar，mmseg4j-solr-1.9.1.jar）拷贝到tomcat的webapps\solr\WEB-INF\lib目录中；（如果tomcat的webapps下面没有solr，请参考《solr学习(1)：solr与tomacat整合》）
2. 根据mmseg目录文件中的README.txt，将下列内容拷贝到E:\solr\tomcat-solr\collection1\conf\schema.xml文件中的types节点下，最好放到最上面：

        <!-- MMsegAnalyzer -->
        <fieldType name="mmseg4j_textComplex" class="solr.TextField" >
              <analyzer>
                <tokenizer class="com.chenlb.mmseg4j.solr.MMSegTokenizerFactory" mode="complex" dicPath="dic"/>
              </analyzer>
            </fieldType>
    	        <fieldType name="mmseg4j_textMaxWord" class="solr.TextField" >
              <analyzer>
                <tokenizer class="com.chenlb.mmseg4j.solr.MMSegTokenizerFactory" mode="max-word" dicPath="dic"/>
              </analyzer>
            </fieldType>
	        <fieldType name="mmseg4j_textSimple" class="solr.TextField" >
              <analyzer>
                <tokenizer class="com.chenlb.mmseg4j.solr.MMSegTokenizerFactory" mode="simple" dicPath="dic"/>
              </analyzer>
        </fieldType>

3. 在下列内容拷贝到E:\solr\tomcat-solr\collection1\conf\schema.xml文件中的fields节点下，最好放到最上面：

        <field name="mmseg4j_complex" type="mmseg4j_textComplex" indexed="true" stored="true" multiValued="true" />
        <field name="mmseg4j_simple" type="mmseg4j_textSimple" indexed="true" stored="true" multiValued="true" />
        <field name="mmseg4j_max_word" type="mmseg4j_textMaxWord" indexed="true" stored="true" multiValued="true" /> 

       **通过以上步骤就可以成功配置mmseg4j分词器到solr中了。**
4. 启动tomcat，登入http://localhost:8080/solr/#/collection1/analysis ，在Field Value (Index)框里面输入要进行分词的句子，在Analyse Fieldname / FieldType选择上面配置的中文分词器，点击Analyse Values按钮进行分词，此时会出现错误TokenStream contract violation: reset()/close() call missing, reset() called multiple times, or subclass does not call super.reset(). Please see Javadocs of TokenStream class for more information about the correct consuming workflow.如图：
![solr_mmseg-1](https://github.com/yuan-jian/blog/blob/gh-pages/images/solr/solr_mmseg-1.png?raw=true)
该原因是源码的一个bug引起的，需要修改上面下载的mmseg4j-analysis-1.9.1.zip解压后的mmseg4j-analysis目录下的类：MMSegTokenizer.java，修改reset()方法并加上下面注释中的这一句：

```java        
        public void reset() throws IOException {
            //lucene 4.0
            //org.apache.lucene.analysis.Tokenizer.setReader(Reader)
            //setReader 自动被调用, input 自动被设置。
            super.reset();   //加这一句
            mmSeg.reset(input);
        }
```

修改后运行mvn clean package -DskipTests进行打包，在mmseg4j-analysis下的target目录中得到最新的mmseg4j-analysis-1.9.2-SNAPSHOT.jar 并替换Tomcat下的solr下的WEB-INF/lib下的mmseg4j-analysis-1.9.1.jar。
5. 重新启动Tomcat，并继续访问上面进行分词的出错页面，此时可以看到bug已经修复，可以使用mmseg中文分词了。
![solr_mmseg-2](https://github.com/yuan-jian/blog/blob/gh-pages/images/solr/solr_mmseg-2.png?raw=true)

* **关于MMSeg词库：**
上面配置fieldType节点的时候我们配置词库的位置是dicPath="dic"，dic是相对于solr.home的路径，由于我们导入的mmseg4j-core-1.9.1.jar中data目录中包含词库（char.dic,units.dic,words.dic三个文件），所以这里就不需要配置了，如果要自己配置词库，这里我们配置的是相对路径，是相对于solr.home的，需要在solr.home路径下新建dic目录并把词库文件放入里面，这里的solr.home是E:\solr\tomcat-solr\collection1目录，所以我们要把这三个词库文件（char.dic,units.dic,words.dic）放到E:\solr\tomcat-solr\collection1\dic目录下就可以了，当然我们也可以将dic换成绝对路径，不用考虑那个是solr.home，如：dicPath="E:\solr\tomcat-solr\collection1\dic"；通过源码分析，chars.dic和units.dic先加载的路径为dicPath配置的路径，如果此路径没有词库文件，则加载jar里面的词库；而words.dic和wordsXXX.dic则是无论jar包中是否存在先加载jar包，然会再加载dicPath,连个路径都会加载。
* **关于词库文件**：
1.data/chars.dic 是单字与语料中的频率，一般不用改动，1.5版本中已经加到mmseg4j的jar里了，我们不需要关心它，当然你在词库目录放这个文件可能覆盖它。
2.data/units.dic 是单字的单位，默认读jar包里的，你也可以自定义覆盖它。
3.data/words.dic 是词库文件，一行一词，当然你也可以使用自己的，1.5版本使用 sogou 词库，1.0的版本是用 rmmseg 带的词库。
4.data/wordsxxx.dic 1.6版支持多个词库文件，data 目录（或你定义的目录）下读到"words"前缀且".dic"为后缀的文件。如：data/words-my.dic。
